import os
import datetime
import pandas as pd
import sqlalchemy
from collections import Counter
from urllib.parse import quote_plus
from dotenv import load_dotenv
from datasets import Dataset
import datetime
import random
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling,
)

# Load environment variables from .env file
load_dotenv()

def create_engine():
    user = 'root'
    password = os.getenv('MYSQL_PASSWORD')
    host = 'localhost'
    db = 'etf'
    if not password:
        raise ValueError("Missing MYSQL_PASSWORD")
    password = quote_plus(password)
    engine_url = f"mysql+pymysql://{user}:{password}@{host}/{db}"
    return sqlalchemy.create_engine(engine_url)

def load_data():
    engine = create_engine()
#Retrieve the ETF and Expense ratio details from the DB
    query = """
        SELECT e.*, r.*
        FROM etf e
        JOIN etf_expenseratio r ON e.etf_id = r.etf_id       
    """
    df = pd.read_sql(query, engine)
    print(f"[INFO] Retrieved {len(df)} rows from the database.")
    
    return pd.read_sql(query, engine)

def conversational_variants(template, *args):
    base = template.format(*args)
    variants = [
        base,
        f"Can you tell me {base[0].lower() + base[1:]}",
        f"Tell me {base[0].lower() + base[1:]}",
        f"Do you know {base.lower()}",
        f"I'm curious, {base.lower()}",
    ]
    return random.sample(variants, 2)

def generate_prompt_response_etfexpenseratio_pairs(df):
    pairs = []
    current_year = datetime.datetime.now().year

    # --- 1. Basic Annual Expense Ratio ---
    for _, row in df.iterrows():
        etf, year, value = row['etf_name'], int(row['year']), row['expense_ratio']
        response = f"The expense ratio of {etf} in {year} was {value:.2f}%."
        for prompt in conversational_variants("What was the expense ratio of {} in {}?", etf, year):
            pairs.append({"prompt": prompt, "response": response})
        for prompt in conversational_variants("Tell me the expense ratio for {} for the year {}.", etf, year):
            pairs.append({"prompt": prompt, "response": response})

    # --- 2. Trend Over N Years ---
    for etf, group in df.groupby("etf_name"):
        for n in [3, 5]:
            years = [current_year - i for i in range(n)][::-1]
            values = group[group['year'].isin(years)].sort_values('year')
            if len(values) == n:
                trend = ", ".join(f"{int(row.year)}: {row.expense_ratio:.2f}%" for _, row in values.iterrows())
                response = f"The expense ratio trend of {etf} over the last {n} years is: {trend}."
                for prompt in conversational_variants("How has the expense ratio of {} changed over the last {} years?", etf, n):
                    pairs.append({"prompt": prompt, "response": response})
                for prompt in conversational_variants("Show me the trend in expense ratio for {} in recent years.", etf):
                    pairs.append({"prompt": prompt, "response": response})

    # --- 3. Lowest/Highest in a Year or N-Year Range ---
    for year in df['year'].unique():
        data = df[df['year'] == year]
        if not data.empty:
            min_row = data.loc[data['expense_ratio'].idxmin()]
            max_row = data.loc[data['expense_ratio'].idxmax()]
            pairs.append({
                "prompt": f"Which ETF had the lowest expense ratio in {int(year)}?",
                "response": f"The ETF with the lowest expense ratio in {int(year)} was {min_row['etf_name']} with {min_row['expense_ratio']:.2f}%."
            })
            pairs.append({
                "prompt": f"Which ETF had the highest expense ratio in {int(year)}?",
                "response": f"The ETF with the highest expense ratio in {int(year)} was {max_row['etf_name']} with {max_row['expense_ratio']:.2f}%."
            })

    for n in [3, 5]:
        years = [current_year - i for i in range(n)]
        subset = df[df['year'].isin(years)]
        avg_expenses = subset.groupby('etf_name')['expense_ratio'].mean()
        if not avg_expenses.empty:
            min_etf, min_val = avg_expenses.idxmin(), avg_expenses.min()
            max_etf, max_val = avg_expenses.idxmax(), avg_expenses.max()
            pairs.append({
                "prompt": f"What ETF had the lowest expense ratio over the last {n} years?",
                "response": f"The ETF with the lowest average expense ratio over the last {n} years was {min_etf} with {min_val:.2f}%."
            })
            pairs.append({
                "prompt": f"What ETF had the highest expense ratio over the last {n} years?",
                "response": f"The ETF with the highest average expense ratio over the last {n} years was {max_etf} with {max_val:.2f}%."
            })

    return pairs

def format_for_causal_lm(example):
    return {"text": f"<s>[Prompt] {example['prompt']} [/Prompt] [Answer] {example['response']} [/Answer]</s>"}


if __name__ == "__main__":
    df = load_data()
    pairs = generate_prompt_response_etfexpenseratio_pairs(df)
    #print("The pair response",pairs)
    
    dataset = Dataset.from_list(pairs)
    dataset = dataset.map(format_for_causal_lm)

    model_id = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(model_id)

    tokenized = dataset.map(
        lambda x: tokenizer(x["text"], truncation=True, padding="max_length", max_length=512),
        batched=True
    )

    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

    training_args = TrainingArguments(
        output_dir="Models/Training/etf_tinyllama_finetuned/",
        per_device_train_batch_size=2,
        num_train_epochs=3,
        save_steps=100,
        save_total_limit=2,
        logging_dir="./logs",
        logging_steps=10,
        fp16=False,  # Not supported on CPU
        report_to="none"
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized,
        tokenizer=tokenizer,
        data_collator=data_collator,
    )

    trainer.train()
    print("Number of training samples:", len(tokenized))

    model.save_pretrained("Models/Training/etf_tinyllama_finetuned_expenseratio/")
    tokenizer.save_pretrained("Models/Training/etf_tinyllama_finetuned_expenseratio/")

